{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed8dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52244624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/hongtan/Downloads/archive/audio_speech_actors_01-24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afc656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from each audio file\n",
    "def extract_features(file_path):\n",
    "    audio, sampling_rate = librosa.load(file_path, sr=22050, duration=None)\n",
    "#     mfccs = librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=30)\n",
    "#     features = np.mean(mfccs.T, axis=0)\n",
    "#     features=np.mean(librosa.feature.melspectrogram(y=audio, sr=sampling_rate).T,axis=0)\n",
    "    \n",
    "    features=np.array([])\n",
    "    \n",
    "    stft=np.abs(librosa.stft(audio))\n",
    "    \n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=30).T, axis=0)\n",
    "\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sampling_rate).T,axis=0)\n",
    "\n",
    "    mel=np.mean(librosa.feature.melspectrogram(y=audio, sr=sampling_rate).T,axis=0)\n",
    "    \n",
    "    features=np.hstack((mfccs, chroma, mel))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(dataset_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
    "            if file.endswith('.wav'):\n",
    "                \n",
    "                emotion = file.split('-')[2]\n",
    "                if int(emotion) == 1:\n",
    "                    label = 'Neutral'\n",
    "                elif int(emotion) == 2:\n",
    "                    label = 'Calm'\n",
    "                elif int(emotion) == 3:\n",
    "                    label = 'Happy'\n",
    "                elif int(emotion) == 4:\n",
    "                    label = 'Sad'\n",
    "                elif int(emotion) == 5:\n",
    "                    label = 'Angry'\n",
    "                elif int(emotion) == 6:\n",
    "                    label = 'Fearful'\n",
    "                elif int(emotion) == 7:\n",
    "                    label = 'Disgust'\n",
    "                elif int(emotion) == 8:\n",
    "                    label = 'Surprised'\n",
    "                else:\n",
    "                    label = 'UNK'\n",
    "                    \n",
    "                file_path = os.path.join(dataset_path, folder, file)\n",
    "                features = extract_features(file_path)\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16718f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1440, 170)\n",
      "Shape of y: (1440,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "X, y = preprocess_data(dataset_path)\n",
    "\n",
    "# Print the shape of the feature matrix and the label array\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35701426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encode y\n",
    "OHE = OneHotEncoder()\n",
    "\n",
    "y = np.array(y).reshape(-1,1)\n",
    "y = OHE.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c97a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1152, 170)\n",
      "y_train: (1152, 8)\n",
      "X_test: (288, 170)\n",
      "y_test: (288, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=29, test_size=0.20, shuffle=True)\n",
    "\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('y_train: {}'.format(y_train.shape))\n",
    "print('X_test: {}'.format(X_test.shape))\n",
    "print('y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7d5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1152, 170)\n",
      "y_train: (1152, 8)\n",
      "X_test: (288, 170)\n",
      "y_test: (288, 8)\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "SS = StandardScaler()\n",
    "\n",
    "X_train = SS.fit_transform(X_train)\n",
    "X_test = SS.transform(X_test)\n",
    "\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('y_train: {}'.format(y_train.shape))\n",
    "print('X_test: {}'.format(X_test.shape))\n",
    "print('y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101d7e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1152, 170, 1)\n",
      "X_test: (288, 170, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('X_test: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d694d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# Function to plot Training Accuracy vs Validation Accuracy\n",
    "def TrainVal_plot(history):\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    train_acc = history.history['accuracy']\n",
    "\n",
    "    epochs = range(0, 300)\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "    plt.plot(epochs, train_acc, 'r', label='Training Accuracy')\n",
    "    plt.title('Training vs. Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce02c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 168, 8)            24        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 168, 8)           32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 84, 8)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 82, 16)            384       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 82, 16)           64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 39, 32)            1536      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 39, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 19, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 608)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                38912     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,856\n",
      "Trainable params: 41,616\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape ,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=0.01)\n",
    "# Compile model with appropriate loss function, optimizer and metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ae4247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 20:25:47.682667: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 5s 13ms/step - loss: 2.1331 - accuracy: 0.2517 - val_loss: 3.6353 - val_accuracy: 0.2188\n",
      "Epoch 2/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9376 - accuracy: 0.2465 - val_loss: 2.5460 - val_accuracy: 0.2292\n",
      "Epoch 3/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9050 - accuracy: 0.2760 - val_loss: 1.8995 - val_accuracy: 0.3090\n",
      "Epoch 4/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8598 - accuracy: 0.2873 - val_loss: 2.4567 - val_accuracy: 0.3299\n",
      "Epoch 5/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8265 - accuracy: 0.3012 - val_loss: 2.0759 - val_accuracy: 0.2917\n",
      "Epoch 6/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8032 - accuracy: 0.3142 - val_loss: 2.5339 - val_accuracy: 0.2847\n",
      "Epoch 7/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7884 - accuracy: 0.3238 - val_loss: 3.2604 - val_accuracy: 0.2188\n",
      "Epoch 8/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8845 - accuracy: 0.2917 - val_loss: 2.3899 - val_accuracy: 0.2535\n",
      "Epoch 9/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8705 - accuracy: 0.2786 - val_loss: 2.4620 - val_accuracy: 0.2743\n",
      "Epoch 10/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8857 - accuracy: 0.2760 - val_loss: 3.2558 - val_accuracy: 0.3056\n",
      "Epoch 11/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8505 - accuracy: 0.2960 - val_loss: 29.2364 - val_accuracy: 0.2500\n",
      "Epoch 12/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8681 - accuracy: 0.2891 - val_loss: 4.0495 - val_accuracy: 0.2118\n",
      "Epoch 13/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8003 - accuracy: 0.3186 - val_loss: 4.5133 - val_accuracy: 0.3472\n",
      "Epoch 14/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7848 - accuracy: 0.3194 - val_loss: 2.2788 - val_accuracy: 0.3229\n",
      "Epoch 15/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7750 - accuracy: 0.3299 - val_loss: 2.5381 - val_accuracy: 0.3854\n",
      "Epoch 16/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7749 - accuracy: 0.3281 - val_loss: 1.7693 - val_accuracy: 0.3507\n",
      "Epoch 17/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8153 - accuracy: 0.3003 - val_loss: 2.5106 - val_accuracy: 0.2917\n",
      "Epoch 18/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7254 - accuracy: 0.3481 - val_loss: 3.6257 - val_accuracy: 0.2361\n",
      "Epoch 19/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7341 - accuracy: 0.3359 - val_loss: 5.2614 - val_accuracy: 0.2674\n",
      "Epoch 20/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7439 - accuracy: 0.3446 - val_loss: 5.9200 - val_accuracy: 0.2118\n",
      "Epoch 21/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7233 - accuracy: 0.3663 - val_loss: 4.5655 - val_accuracy: 0.2708\n",
      "Epoch 22/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7161 - accuracy: 0.3984 - val_loss: 3.4084 - val_accuracy: 0.3090\n",
      "Epoch 23/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6611 - accuracy: 0.3872 - val_loss: 5.4502 - val_accuracy: 0.3611\n",
      "Epoch 24/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6714 - accuracy: 0.3845 - val_loss: 7.5625 - val_accuracy: 0.2222\n",
      "Epoch 25/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6513 - accuracy: 0.3967 - val_loss: 5.3588 - val_accuracy: 0.2535\n",
      "Epoch 26/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6839 - accuracy: 0.3741 - val_loss: 5.0762 - val_accuracy: 0.2396\n",
      "Epoch 27/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6615 - accuracy: 0.4054 - val_loss: 7.7637 - val_accuracy: 0.2396\n",
      "Epoch 28/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6630 - accuracy: 0.4201 - val_loss: 8.5800 - val_accuracy: 0.2812\n",
      "Epoch 29/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6062 - accuracy: 0.4271 - val_loss: 6.7271 - val_accuracy: 0.1146\n",
      "Epoch 30/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6297 - accuracy: 0.3993 - val_loss: 3.0241 - val_accuracy: 0.3125\n",
      "Epoch 31/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6301 - accuracy: 0.3993 - val_loss: 4.1283 - val_accuracy: 0.3056\n",
      "Epoch 32/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6491 - accuracy: 0.4054 - val_loss: 5.0869 - val_accuracy: 0.3021\n",
      "Epoch 33/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6231 - accuracy: 0.4045 - val_loss: 7.0622 - val_accuracy: 0.3785\n",
      "Epoch 34/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6149 - accuracy: 0.4097 - val_loss: 7.3893 - val_accuracy: 0.3125\n",
      "Epoch 35/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5942 - accuracy: 0.4201 - val_loss: 12.2954 - val_accuracy: 0.2708\n",
      "Epoch 36/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5728 - accuracy: 0.4193 - val_loss: 6.2941 - val_accuracy: 0.3194\n",
      "Epoch 37/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6352 - accuracy: 0.4010 - val_loss: 6.0178 - val_accuracy: 0.3924\n",
      "Epoch 38/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5652 - accuracy: 0.4505 - val_loss: 7.3233 - val_accuracy: 0.3646\n",
      "Epoch 39/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5692 - accuracy: 0.4349 - val_loss: 8.5788 - val_accuracy: 0.3264\n",
      "Epoch 40/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6160 - accuracy: 0.4201 - val_loss: 9.3958 - val_accuracy: 0.3542\n",
      "Epoch 41/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5586 - accuracy: 0.4340 - val_loss: 7.0147 - val_accuracy: 0.3750\n",
      "Epoch 42/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5659 - accuracy: 0.4227 - val_loss: 2.9484 - val_accuracy: 0.3993\n",
      "Epoch 43/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5638 - accuracy: 0.4609 - val_loss: 8.2016 - val_accuracy: 0.3889\n",
      "Epoch 44/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5012 - accuracy: 0.4661 - val_loss: 7.2881 - val_accuracy: 0.3125\n",
      "Epoch 45/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5637 - accuracy: 0.4375 - val_loss: 7.3930 - val_accuracy: 0.3542\n",
      "Epoch 46/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5628 - accuracy: 0.4253 - val_loss: 8.9990 - val_accuracy: 0.3194\n",
      "Epoch 47/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5637 - accuracy: 0.4418 - val_loss: 10.5189 - val_accuracy: 0.2986\n",
      "Epoch 48/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6360 - accuracy: 0.4184 - val_loss: 10.7943 - val_accuracy: 0.2951\n",
      "Epoch 49/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5360 - accuracy: 0.4575 - val_loss: 6.7491 - val_accuracy: 0.3715\n",
      "Epoch 50/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5024 - accuracy: 0.4705 - val_loss: 8.2863 - val_accuracy: 0.3889\n",
      "Epoch 51/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5607 - accuracy: 0.4453 - val_loss: 2.7404 - val_accuracy: 0.3542\n",
      "Epoch 52/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4924 - accuracy: 0.4523 - val_loss: 5.5831 - val_accuracy: 0.4410\n",
      "Epoch 53/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5373 - accuracy: 0.4505 - val_loss: 21.4531 - val_accuracy: 0.4201\n",
      "Epoch 54/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4988 - accuracy: 0.4792 - val_loss: 9.0911 - val_accuracy: 0.4549\n",
      "Epoch 55/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4832 - accuracy: 0.4601 - val_loss: 13.4327 - val_accuracy: 0.3924\n",
      "Epoch 56/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4182 - accuracy: 0.4974 - val_loss: 16.7705 - val_accuracy: 0.3576\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4673 - accuracy: 0.4722 - val_loss: 17.6077 - val_accuracy: 0.4306\n",
      "Epoch 58/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4500 - accuracy: 0.4905 - val_loss: 14.3759 - val_accuracy: 0.3958\n",
      "Epoch 59/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3784 - accuracy: 0.5182 - val_loss: 13.0735 - val_accuracy: 0.4271\n",
      "Epoch 60/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4671 - accuracy: 0.4774 - val_loss: 16.2631 - val_accuracy: 0.3750\n",
      "Epoch 61/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4436 - accuracy: 0.4931 - val_loss: 8.6371 - val_accuracy: 0.4549\n",
      "Epoch 62/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3888 - accuracy: 0.5148 - val_loss: 14.4472 - val_accuracy: 0.4132\n",
      "Epoch 63/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3614 - accuracy: 0.5217 - val_loss: 13.3072 - val_accuracy: 0.3958\n",
      "Epoch 64/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3917 - accuracy: 0.4983 - val_loss: 6.5768 - val_accuracy: 0.3854\n",
      "Epoch 65/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3626 - accuracy: 0.5295 - val_loss: 14.2477 - val_accuracy: 0.3924\n",
      "Epoch 66/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3430 - accuracy: 0.5148 - val_loss: 10.1125 - val_accuracy: 0.3472\n",
      "Epoch 67/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2952 - accuracy: 0.5451 - val_loss: 12.6943 - val_accuracy: 0.4444\n",
      "Epoch 68/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3541 - accuracy: 0.5182 - val_loss: 4.5258 - val_accuracy: 0.3507\n",
      "Epoch 69/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3358 - accuracy: 0.5226 - val_loss: 14.0549 - val_accuracy: 0.4444\n",
      "Epoch 70/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2881 - accuracy: 0.5616 - val_loss: 19.7076 - val_accuracy: 0.4236\n",
      "Epoch 71/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4097 - accuracy: 0.5035 - val_loss: 10.2415 - val_accuracy: 0.4688\n",
      "Epoch 72/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3734 - accuracy: 0.5087 - val_loss: 8.5039 - val_accuracy: 0.3750\n",
      "Epoch 73/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3556 - accuracy: 0.5139 - val_loss: 13.7901 - val_accuracy: 0.3750\n",
      "Epoch 74/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3272 - accuracy: 0.5347 - val_loss: 35.3699 - val_accuracy: 0.4340\n",
      "Epoch 75/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3078 - accuracy: 0.5425 - val_loss: 11.8868 - val_accuracy: 0.4062\n",
      "Epoch 76/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2810 - accuracy: 0.5625 - val_loss: 25.2413 - val_accuracy: 0.4340\n",
      "Epoch 77/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4901 - accuracy: 0.4766 - val_loss: 12.2635 - val_accuracy: 0.2326\n",
      "Epoch 78/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5163 - accuracy: 0.4870 - val_loss: 7.2465 - val_accuracy: 0.3785\n",
      "Epoch 79/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4195 - accuracy: 0.5104 - val_loss: 2.7584 - val_accuracy: 0.3750\n",
      "Epoch 80/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4060 - accuracy: 0.4835 - val_loss: 2.5716 - val_accuracy: 0.3958\n",
      "Epoch 81/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4020 - accuracy: 0.4878 - val_loss: 2.3547 - val_accuracy: 0.4340\n",
      "Epoch 82/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4059 - accuracy: 0.5139 - val_loss: 2.7374 - val_accuracy: 0.3611\n",
      "Epoch 83/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3456 - accuracy: 0.5217 - val_loss: 2.5162 - val_accuracy: 0.4479\n",
      "Epoch 84/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3176 - accuracy: 0.5330 - val_loss: 2.2948 - val_accuracy: 0.4479\n",
      "Epoch 85/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2487 - accuracy: 0.5599 - val_loss: 2.3230 - val_accuracy: 0.4062\n",
      "Epoch 86/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2606 - accuracy: 0.5590 - val_loss: 3.1083 - val_accuracy: 0.4236\n",
      "Epoch 87/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3287 - accuracy: 0.5460 - val_loss: 3.9485 - val_accuracy: 0.3333\n",
      "Epoch 88/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3356 - accuracy: 0.5208 - val_loss: 3.9354 - val_accuracy: 0.3785\n",
      "Epoch 89/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2799 - accuracy: 0.5365 - val_loss: 7.5475 - val_accuracy: 0.3889\n",
      "Epoch 90/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3166 - accuracy: 0.5382 - val_loss: 2.0942 - val_accuracy: 0.4167\n",
      "Epoch 91/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2751 - accuracy: 0.5538 - val_loss: 2.8103 - val_accuracy: 0.4479\n",
      "Epoch 92/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2067 - accuracy: 0.5894 - val_loss: 6.4968 - val_accuracy: 0.4514\n",
      "Epoch 93/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2630 - accuracy: 0.5530 - val_loss: 8.0048 - val_accuracy: 0.3924\n",
      "Epoch 94/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2448 - accuracy: 0.5582 - val_loss: 9.0111 - val_accuracy: 0.4479\n",
      "Epoch 95/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2504 - accuracy: 0.5677 - val_loss: 11.3834 - val_accuracy: 0.3750\n",
      "Epoch 96/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2278 - accuracy: 0.5512 - val_loss: 27.9242 - val_accuracy: 0.3889\n",
      "Epoch 97/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2508 - accuracy: 0.5651 - val_loss: 22.1391 - val_accuracy: 0.2812\n",
      "Epoch 98/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3898 - accuracy: 0.5130 - val_loss: 8.8542 - val_accuracy: 0.3854\n",
      "Epoch 99/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4245 - accuracy: 0.4861 - val_loss: 14.7742 - val_accuracy: 0.4514\n",
      "Epoch 100/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3078 - accuracy: 0.5321 - val_loss: 13.8113 - val_accuracy: 0.4201\n",
      "Epoch 101/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2688 - accuracy: 0.5564 - val_loss: 9.2055 - val_accuracy: 0.4444\n",
      "Epoch 102/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2127 - accuracy: 0.5773 - val_loss: 7.9919 - val_accuracy: 0.4618\n",
      "Epoch 103/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2247 - accuracy: 0.5755 - val_loss: 16.0971 - val_accuracy: 0.4514\n",
      "Epoch 104/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1998 - accuracy: 0.5807 - val_loss: 21.1120 - val_accuracy: 0.4722\n",
      "Epoch 105/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2360 - accuracy: 0.5807 - val_loss: 14.2236 - val_accuracy: 0.4514\n",
      "Epoch 106/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1430 - accuracy: 0.6050 - val_loss: 22.1478 - val_accuracy: 0.4514\n",
      "Epoch 107/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1832 - accuracy: 0.5929 - val_loss: 15.8541 - val_accuracy: 0.3993\n",
      "Epoch 108/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1318 - accuracy: 0.6198 - val_loss: 22.2647 - val_accuracy: 0.3889\n",
      "Epoch 109/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1681 - accuracy: 0.6076 - val_loss: 22.4672 - val_accuracy: 0.4479\n",
      "Epoch 110/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1540 - accuracy: 0.6120 - val_loss: 22.5913 - val_accuracy: 0.4618\n",
      "Epoch 111/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1500 - accuracy: 0.6102 - val_loss: 17.4575 - val_accuracy: 0.4583\n",
      "Epoch 112/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1192 - accuracy: 0.6302 - val_loss: 25.1704 - val_accuracy: 0.4236\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2075 - accuracy: 0.5955 - val_loss: 19.4994 - val_accuracy: 0.4410\n",
      "Epoch 114/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1652 - accuracy: 0.5998 - val_loss: 6.3153 - val_accuracy: 0.4444\n",
      "Epoch 115/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1187 - accuracy: 0.6215 - val_loss: 41.4828 - val_accuracy: 0.4201\n",
      "Epoch 116/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1596 - accuracy: 0.6137 - val_loss: 11.0008 - val_accuracy: 0.4722\n",
      "Epoch 117/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1346 - accuracy: 0.6024 - val_loss: 8.9957 - val_accuracy: 0.4306\n",
      "Epoch 118/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1586 - accuracy: 0.6111 - val_loss: 22.7043 - val_accuracy: 0.4618\n",
      "Epoch 119/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1401 - accuracy: 0.6068 - val_loss: 25.8153 - val_accuracy: 0.4479\n",
      "Epoch 120/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0798 - accuracy: 0.6233 - val_loss: 15.2043 - val_accuracy: 0.4583\n",
      "Epoch 121/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1747 - accuracy: 0.5877 - val_loss: 42.6084 - val_accuracy: 0.4375\n",
      "Epoch 122/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2014 - accuracy: 0.6155 - val_loss: 5.5597 - val_accuracy: 0.3924\n",
      "Epoch 123/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1183 - accuracy: 0.6293 - val_loss: 8.0494 - val_accuracy: 0.4410\n",
      "Epoch 124/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0744 - accuracy: 0.6450 - val_loss: 10.0560 - val_accuracy: 0.4132\n",
      "Epoch 125/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0109 - accuracy: 0.6519 - val_loss: 5.8751 - val_accuracy: 0.4549\n",
      "Epoch 126/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1138 - accuracy: 0.6007 - val_loss: 9.9166 - val_accuracy: 0.4340\n",
      "Epoch 127/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0713 - accuracy: 0.6302 - val_loss: 11.2858 - val_accuracy: 0.4375\n",
      "Epoch 128/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0881 - accuracy: 0.6207 - val_loss: 7.6590 - val_accuracy: 0.4514\n",
      "Epoch 129/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1374 - accuracy: 0.5938 - val_loss: 7.0521 - val_accuracy: 0.4931\n",
      "Epoch 130/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1160 - accuracy: 0.6146 - val_loss: 12.5644 - val_accuracy: 0.4410\n",
      "Epoch 131/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0149 - accuracy: 0.6458 - val_loss: 15.8162 - val_accuracy: 0.4132\n",
      "Epoch 132/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2513 - accuracy: 0.5720 - val_loss: 34.1215 - val_accuracy: 0.3958\n",
      "Epoch 133/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2919 - accuracy: 0.5503 - val_loss: 14.4912 - val_accuracy: 0.4201\n",
      "Epoch 134/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1922 - accuracy: 0.5964 - val_loss: 10.6090 - val_accuracy: 0.4375\n",
      "Epoch 135/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1456 - accuracy: 0.6068 - val_loss: 16.6471 - val_accuracy: 0.4514\n",
      "Epoch 136/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1649 - accuracy: 0.5833 - val_loss: 4.7612 - val_accuracy: 0.3924\n",
      "Epoch 137/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0805 - accuracy: 0.6450 - val_loss: 2.8378 - val_accuracy: 0.4306\n",
      "Epoch 138/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0804 - accuracy: 0.6189 - val_loss: 4.5892 - val_accuracy: 0.4167\n",
      "Epoch 139/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.0861 - accuracy: 0.6319 - val_loss: 3.0287 - val_accuracy: 0.4583\n",
      "Epoch 140/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.0679 - accuracy: 0.6519 - val_loss: 7.8803 - val_accuracy: 0.4167\n",
      "Epoch 141/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.0162 - accuracy: 0.6545 - val_loss: 7.9263 - val_accuracy: 0.4236\n",
      "Epoch 142/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.9684 - accuracy: 0.6606 - val_loss: 7.4453 - val_accuracy: 0.4375\n",
      "Epoch 143/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.0296 - accuracy: 0.6467 - val_loss: 8.6238 - val_accuracy: 0.4097\n",
      "Epoch 144/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0197 - accuracy: 0.6536 - val_loss: 2.5002 - val_accuracy: 0.4410\n",
      "Epoch 145/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0087 - accuracy: 0.6484 - val_loss: 11.2631 - val_accuracy: 0.3993\n",
      "Epoch 146/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0403 - accuracy: 0.6484 - val_loss: 5.9141 - val_accuracy: 0.3785\n",
      "Epoch 147/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0003 - accuracy: 0.6519 - val_loss: 3.6622 - val_accuracy: 0.4479\n",
      "Epoch 148/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0299 - accuracy: 0.6493 - val_loss: 4.7069 - val_accuracy: 0.4340\n",
      "Epoch 149/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9747 - accuracy: 0.6684 - val_loss: 6.9582 - val_accuracy: 0.4444\n",
      "Epoch 150/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9900 - accuracy: 0.6736 - val_loss: 6.6418 - val_accuracy: 0.4201\n",
      "Epoch 151/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2541 - accuracy: 0.5660 - val_loss: 2.2489 - val_accuracy: 0.4444\n",
      "Epoch 152/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.0674 - accuracy: 0.6345 - val_loss: 12.7146 - val_accuracy: 0.4583\n",
      "Epoch 153/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.0803 - accuracy: 0.6276 - val_loss: 12.5740 - val_accuracy: 0.4618\n",
      "Epoch 154/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9564 - accuracy: 0.6832 - val_loss: 7.0394 - val_accuracy: 0.4722\n",
      "Epoch 155/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9426 - accuracy: 0.6997 - val_loss: 10.2305 - val_accuracy: 0.4410\n",
      "Epoch 156/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9467 - accuracy: 0.6814 - val_loss: 5.8404 - val_accuracy: 0.4444\n",
      "Epoch 157/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1090 - accuracy: 0.6250 - val_loss: 4.0163 - val_accuracy: 0.4444\n",
      "Epoch 158/300\n",
      "288/288 [==============================] - 4s 12ms/step - loss: 0.9499 - accuracy: 0.6736 - val_loss: 6.7325 - val_accuracy: 0.4236\n",
      "Epoch 159/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9391 - accuracy: 0.6780 - val_loss: 21.4017 - val_accuracy: 0.4792\n",
      "Epoch 160/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8766 - accuracy: 0.6962 - val_loss: 26.0101 - val_accuracy: 0.4375\n",
      "Epoch 161/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9373 - accuracy: 0.6979 - val_loss: 16.1177 - val_accuracy: 0.4653\n",
      "Epoch 162/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.9224 - accuracy: 0.6901 - val_loss: 12.7151 - val_accuracy: 0.4410\n",
      "Epoch 163/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.8967 - accuracy: 0.7049 - val_loss: 8.6324 - val_accuracy: 0.4688\n",
      "Epoch 164/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.0106 - accuracy: 0.6736 - val_loss: 5.7155 - val_accuracy: 0.4688\n",
      "Epoch 165/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0318 - accuracy: 0.6424 - val_loss: 6.5048 - val_accuracy: 0.4410\n",
      "Epoch 166/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9898 - accuracy: 0.6762 - val_loss: 14.8836 - val_accuracy: 0.3993\n",
      "Epoch 167/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9887 - accuracy: 0.6623 - val_loss: 22.7344 - val_accuracy: 0.4826\n",
      "Epoch 168/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9355 - accuracy: 0.6762 - val_loss: 32.7918 - val_accuracy: 0.4583\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1228 - accuracy: 0.6554 - val_loss: 36.2416 - val_accuracy: 0.4097\n",
      "Epoch 170/300\n",
      "288/288 [==============================] - 4s 12ms/step - loss: 1.0440 - accuracy: 0.6415 - val_loss: 54.9712 - val_accuracy: 0.4097\n",
      "Epoch 171/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0288 - accuracy: 0.6467 - val_loss: 43.0577 - val_accuracy: 0.4931\n",
      "Epoch 172/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9503 - accuracy: 0.6719 - val_loss: 32.5103 - val_accuracy: 0.4410\n",
      "Epoch 173/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9219 - accuracy: 0.6797 - val_loss: 22.9471 - val_accuracy: 0.4792\n",
      "Epoch 174/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9312 - accuracy: 0.6892 - val_loss: 21.1501 - val_accuracy: 0.4514\n",
      "Epoch 175/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9248 - accuracy: 0.6962 - val_loss: 25.5151 - val_accuracy: 0.4618\n",
      "Epoch 176/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8489 - accuracy: 0.7179 - val_loss: 20.1503 - val_accuracy: 0.5069\n",
      "Epoch 177/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9278 - accuracy: 0.6936 - val_loss: 28.1208 - val_accuracy: 0.4688\n",
      "Epoch 178/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9119 - accuracy: 0.6901 - val_loss: 51.0832 - val_accuracy: 0.4479\n",
      "Epoch 179/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9103 - accuracy: 0.6953 - val_loss: 34.9753 - val_accuracy: 0.4931\n",
      "Epoch 180/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9159 - accuracy: 0.6918 - val_loss: 27.2415 - val_accuracy: 0.4757\n",
      "Epoch 181/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8991 - accuracy: 0.7161 - val_loss: 6.6840 - val_accuracy: 0.4896\n",
      "Epoch 182/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8774 - accuracy: 0.7144 - val_loss: 10.9215 - val_accuracy: 0.4410\n",
      "Epoch 183/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8736 - accuracy: 0.7040 - val_loss: 10.3968 - val_accuracy: 0.5243\n",
      "Epoch 184/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8572 - accuracy: 0.7179 - val_loss: 33.1522 - val_accuracy: 0.4444\n",
      "Epoch 185/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9223 - accuracy: 0.7023 - val_loss: 48.8165 - val_accuracy: 0.4826\n",
      "Epoch 186/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9308 - accuracy: 0.6866 - val_loss: 25.4088 - val_accuracy: 0.5035\n",
      "Epoch 187/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9126 - accuracy: 0.6849 - val_loss: 23.7054 - val_accuracy: 0.4583\n",
      "Epoch 188/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8791 - accuracy: 0.7083 - val_loss: 17.5744 - val_accuracy: 0.4236\n",
      "Epoch 189/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8144 - accuracy: 0.7309 - val_loss: 22.3011 - val_accuracy: 0.4549\n",
      "Epoch 190/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8038 - accuracy: 0.7144 - val_loss: 19.1499 - val_accuracy: 0.4653\n",
      "Epoch 191/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8911 - accuracy: 0.6927 - val_loss: 7.1409 - val_accuracy: 0.4826\n",
      "Epoch 192/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8390 - accuracy: 0.7188 - val_loss: 20.0549 - val_accuracy: 0.4583\n",
      "Epoch 193/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8945 - accuracy: 0.7205 - val_loss: 31.9308 - val_accuracy: 0.4549\n",
      "Epoch 194/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8719 - accuracy: 0.7014 - val_loss: 32.6466 - val_accuracy: 0.4618\n",
      "Epoch 195/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9416 - accuracy: 0.6797 - val_loss: 47.6061 - val_accuracy: 0.4583\n",
      "Epoch 196/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9803 - accuracy: 0.6641 - val_loss: 13.8780 - val_accuracy: 0.4549\n",
      "Epoch 197/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9183 - accuracy: 0.6944 - val_loss: 15.8688 - val_accuracy: 0.4583\n",
      "Epoch 198/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8987 - accuracy: 0.6858 - val_loss: 18.5748 - val_accuracy: 0.4896\n",
      "Epoch 199/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8922 - accuracy: 0.7083 - val_loss: 20.6604 - val_accuracy: 0.4757\n",
      "Epoch 200/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8613 - accuracy: 0.6997 - val_loss: 22.1725 - val_accuracy: 0.4722\n",
      "Epoch 201/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7300 - accuracy: 0.7396 - val_loss: 14.9324 - val_accuracy: 0.4618\n",
      "Epoch 202/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7916 - accuracy: 0.7300 - val_loss: 9.6285 - val_accuracy: 0.3958\n",
      "Epoch 203/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8032 - accuracy: 0.7300 - val_loss: 13.0542 - val_accuracy: 0.4062\n",
      "Epoch 204/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8716 - accuracy: 0.7057 - val_loss: 62.4578 - val_accuracy: 0.4514\n",
      "Epoch 205/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9225 - accuracy: 0.6823 - val_loss: 21.5638 - val_accuracy: 0.4583\n",
      "Epoch 206/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9487 - accuracy: 0.6892 - val_loss: 63.2529 - val_accuracy: 0.4375\n",
      "Epoch 207/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8780 - accuracy: 0.7109 - val_loss: 30.4496 - val_accuracy: 0.4618\n",
      "Epoch 208/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8410 - accuracy: 0.7127 - val_loss: 19.7700 - val_accuracy: 0.5069\n",
      "Epoch 209/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8539 - accuracy: 0.7144 - val_loss: 16.3102 - val_accuracy: 0.4826\n",
      "Epoch 210/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7982 - accuracy: 0.7335 - val_loss: 9.7745 - val_accuracy: 0.5069\n",
      "Epoch 211/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7911 - accuracy: 0.7344 - val_loss: 23.2219 - val_accuracy: 0.5104\n",
      "Epoch 212/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8058 - accuracy: 0.7153 - val_loss: 13.2261 - val_accuracy: 0.5069\n",
      "Epoch 213/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7747 - accuracy: 0.7335 - val_loss: 26.8873 - val_accuracy: 0.4826\n",
      "Epoch 214/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8396 - accuracy: 0.7214 - val_loss: 11.5928 - val_accuracy: 0.4896\n",
      "Epoch 215/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8504 - accuracy: 0.7196 - val_loss: 13.1025 - val_accuracy: 0.4757\n",
      "Epoch 216/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8453 - accuracy: 0.7283 - val_loss: 21.8834 - val_accuracy: 0.4549\n",
      "Epoch 217/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7717 - accuracy: 0.7344 - val_loss: 7.2518 - val_accuracy: 0.4549\n",
      "Epoch 218/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7595 - accuracy: 0.7465 - val_loss: 125.1833 - val_accuracy: 0.5347\n",
      "Epoch 219/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7267 - accuracy: 0.7682 - val_loss: 137.3991 - val_accuracy: 0.4583\n",
      "Epoch 220/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8281 - accuracy: 0.7309 - val_loss: 13.8855 - val_accuracy: 0.4757\n",
      "Epoch 221/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.9897 - accuracy: 0.6823 - val_loss: 4.4597 - val_accuracy: 0.4236\n",
      "Epoch 222/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1507 - accuracy: 0.6128 - val_loss: 3.9768 - val_accuracy: 0.4896\n",
      "Epoch 223/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8818 - accuracy: 0.6936 - val_loss: 7.7377 - val_accuracy: 0.4375\n",
      "Epoch 224/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9550 - accuracy: 0.6641 - val_loss: 4.7824 - val_accuracy: 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0830 - accuracy: 0.6233 - val_loss: 3.9246 - val_accuracy: 0.4965\n",
      "Epoch 226/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0114 - accuracy: 0.6406 - val_loss: 16.1040 - val_accuracy: 0.4549\n",
      "Epoch 227/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.0094 - accuracy: 0.6623 - val_loss: 14.7665 - val_accuracy: 0.4826\n",
      "Epoch 228/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.9281 - accuracy: 0.6962 - val_loss: 17.8252 - val_accuracy: 0.5035\n",
      "Epoch 229/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8983 - accuracy: 0.7049 - val_loss: 9.9675 - val_accuracy: 0.5174\n",
      "Epoch 230/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7903 - accuracy: 0.7396 - val_loss: 9.5029 - val_accuracy: 0.4583\n",
      "Epoch 231/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7836 - accuracy: 0.7370 - val_loss: 11.7096 - val_accuracy: 0.4792\n",
      "Epoch 232/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8212 - accuracy: 0.7300 - val_loss: 16.3944 - val_accuracy: 0.4653\n",
      "Epoch 233/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8734 - accuracy: 0.6970 - val_loss: 16.6446 - val_accuracy: 0.4236\n",
      "Epoch 234/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8148 - accuracy: 0.7309 - val_loss: 12.9194 - val_accuracy: 0.4757\n",
      "Epoch 235/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.9227 - accuracy: 0.7014 - val_loss: 16.8505 - val_accuracy: 0.4132\n",
      "Epoch 236/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.9485 - accuracy: 0.6771 - val_loss: 8.8566 - val_accuracy: 0.4757\n",
      "Epoch 237/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8279 - accuracy: 0.7257 - val_loss: 12.7270 - val_accuracy: 0.4618\n",
      "Epoch 238/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.8148 - accuracy: 0.7231 - val_loss: 13.8786 - val_accuracy: 0.5000\n",
      "Epoch 239/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7824 - accuracy: 0.7283 - val_loss: 8.9920 - val_accuracy: 0.4931\n",
      "Epoch 240/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.8207 - accuracy: 0.7344 - val_loss: 7.8483 - val_accuracy: 0.4583\n",
      "Epoch 241/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8144 - accuracy: 0.7231 - val_loss: 7.2528 - val_accuracy: 0.5035\n",
      "Epoch 242/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8202 - accuracy: 0.7240 - val_loss: 6.7072 - val_accuracy: 0.4688\n",
      "Epoch 243/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8724 - accuracy: 0.7196 - val_loss: 5.6187 - val_accuracy: 0.4965\n",
      "Epoch 244/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8611 - accuracy: 0.7144 - val_loss: 5.6589 - val_accuracy: 0.4653\n",
      "Epoch 245/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7657 - accuracy: 0.7387 - val_loss: 7.2829 - val_accuracy: 0.4653\n",
      "Epoch 246/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8046 - accuracy: 0.7457 - val_loss: 4.0352 - val_accuracy: 0.4236\n",
      "Epoch 247/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7430 - accuracy: 0.7439 - val_loss: 3.5748 - val_accuracy: 0.4722\n",
      "Epoch 248/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8102 - accuracy: 0.7318 - val_loss: 16.3669 - val_accuracy: 0.4444\n",
      "Epoch 249/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.7452 - accuracy: 0.7500 - val_loss: 6.8824 - val_accuracy: 0.4618\n",
      "Epoch 250/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7968 - accuracy: 0.7257 - val_loss: 8.4457 - val_accuracy: 0.4479\n",
      "Epoch 251/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7537 - accuracy: 0.7561 - val_loss: 9.8177 - val_accuracy: 0.4861\n",
      "Epoch 252/300\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.7627 - accuracy: 0.7439 - val_loss: 11.1632 - val_accuracy: 0.4896\n",
      "Epoch 253/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.8160 - accuracy: 0.7300 - val_loss: 9.8033 - val_accuracy: 0.4757\n",
      "Epoch 254/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8196 - accuracy: 0.7405 - val_loss: 39.3341 - val_accuracy: 0.4236\n",
      "Epoch 255/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7539 - accuracy: 0.7561 - val_loss: 28.1647 - val_accuracy: 0.5035\n",
      "Epoch 256/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.8081 - accuracy: 0.7335 - val_loss: 7.9831 - val_accuracy: 0.4618\n",
      "Epoch 257/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7607 - accuracy: 0.7439 - val_loss: 5.4880 - val_accuracy: 0.4792\n",
      "Epoch 258/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8041 - accuracy: 0.7118 - val_loss: 7.2641 - val_accuracy: 0.4514\n",
      "Epoch 259/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7373 - accuracy: 0.7561 - val_loss: 7.7544 - val_accuracy: 0.5035\n",
      "Epoch 260/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7335 - accuracy: 0.7465 - val_loss: 4.5860 - val_accuracy: 0.4722\n",
      "Epoch 261/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7362 - accuracy: 0.7552 - val_loss: 52.6203 - val_accuracy: 0.3056\n",
      "Epoch 262/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8481 - accuracy: 0.7153 - val_loss: 71.0889 - val_accuracy: 0.4688\n",
      "Epoch 263/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7084 - accuracy: 0.7622 - val_loss: 39.9373 - val_accuracy: 0.4549\n",
      "Epoch 264/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7700 - accuracy: 0.7318 - val_loss: 19.6263 - val_accuracy: 0.4653\n",
      "Epoch 265/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8107 - accuracy: 0.7431 - val_loss: 12.4136 - val_accuracy: 0.4618\n",
      "Epoch 266/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7584 - accuracy: 0.7439 - val_loss: 17.6937 - val_accuracy: 0.4653\n",
      "Epoch 267/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7357 - accuracy: 0.7500 - val_loss: 13.3925 - val_accuracy: 0.4757\n",
      "Epoch 268/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.6984 - accuracy: 0.7656 - val_loss: 8.5655 - val_accuracy: 0.4792\n",
      "Epoch 269/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8087 - accuracy: 0.7300 - val_loss: 3.0185 - val_accuracy: 0.4618\n",
      "Epoch 270/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7271 - accuracy: 0.7517 - val_loss: 6.0927 - val_accuracy: 0.4757\n",
      "Epoch 271/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7416 - accuracy: 0.7431 - val_loss: 6.4233 - val_accuracy: 0.5278\n",
      "Epoch 272/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.7156 - accuracy: 0.7587 - val_loss: 6.9049 - val_accuracy: 0.4583\n",
      "Epoch 273/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8541 - accuracy: 0.7161 - val_loss: 6.4705 - val_accuracy: 0.4271\n",
      "Epoch 274/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8615 - accuracy: 0.7196 - val_loss: 7.3789 - val_accuracy: 0.4896\n",
      "Epoch 275/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8660 - accuracy: 0.7135 - val_loss: 6.8615 - val_accuracy: 0.4931\n",
      "Epoch 276/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8181 - accuracy: 0.7266 - val_loss: 3.0327 - val_accuracy: 0.4931\n",
      "Epoch 277/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7831 - accuracy: 0.7526 - val_loss: 8.5403 - val_accuracy: 0.4479\n",
      "Epoch 278/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7808 - accuracy: 0.7396 - val_loss: 12.9767 - val_accuracy: 0.4722\n",
      "Epoch 279/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8586 - accuracy: 0.7222 - val_loss: 28.1999 - val_accuracy: 0.4444\n",
      "Epoch 280/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.8285 - accuracy: 0.7214 - val_loss: 9.3936 - val_accuracy: 0.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7660 - accuracy: 0.7413 - val_loss: 8.4146 - val_accuracy: 0.4653\n",
      "Epoch 282/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.9374 - accuracy: 0.6962 - val_loss: 4.9071 - val_accuracy: 0.4340\n",
      "Epoch 283/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.8032 - accuracy: 0.7283 - val_loss: 6.9323 - val_accuracy: 0.4653\n",
      "Epoch 284/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8196 - accuracy: 0.7135 - val_loss: 2.8217 - val_accuracy: 0.3993\n",
      "Epoch 285/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.8066 - accuracy: 0.7292 - val_loss: 3.1788 - val_accuracy: 0.4618\n",
      "Epoch 286/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7666 - accuracy: 0.7326 - val_loss: 7.2156 - val_accuracy: 0.4583\n",
      "Epoch 287/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.7140 - accuracy: 0.7622 - val_loss: 5.8328 - val_accuracy: 0.4722\n",
      "Epoch 288/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.6801 - accuracy: 0.7769 - val_loss: 4.6109 - val_accuracy: 0.4583\n",
      "Epoch 289/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7523 - accuracy: 0.7569 - val_loss: 10.4163 - val_accuracy: 0.4583\n",
      "Epoch 290/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7551 - accuracy: 0.7561 - val_loss: 5.5516 - val_accuracy: 0.4792\n",
      "Epoch 291/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7920 - accuracy: 0.7370 - val_loss: 5.5705 - val_accuracy: 0.4618\n",
      "Epoch 292/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.6683 - accuracy: 0.7674 - val_loss: 16.9483 - val_accuracy: 0.5000\n",
      "Epoch 293/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.6866 - accuracy: 0.7726 - val_loss: 3.6196 - val_accuracy: 0.4826\n",
      "Epoch 294/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7152 - accuracy: 0.7639 - val_loss: 12.1366 - val_accuracy: 0.4653\n",
      "Epoch 295/300\n",
      "288/288 [==============================] - 4s 12ms/step - loss: 0.7804 - accuracy: 0.7370 - val_loss: 19.6902 - val_accuracy: 0.4444\n",
      "Epoch 296/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7294 - accuracy: 0.7604 - val_loss: 24.1894 - val_accuracy: 0.4410\n",
      "Epoch 297/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7761 - accuracy: 0.7396 - val_loss: 23.5222 - val_accuracy: 0.4167\n",
      "Epoch 298/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7499 - accuracy: 0.7535 - val_loss: 59.4311 - val_accuracy: 0.5174\n",
      "Epoch 299/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.7857 - accuracy: 0.7500 - val_loss: 21.3150 - val_accuracy: 0.4583\n",
      "Epoch 300/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.6946 - accuracy: 0.7665 - val_loss: 11.3561 - val_accuracy: 0.5035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4, epochs=300, validation_data=(X_test, y_test),)\n",
    "# callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b37e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 5.0681 - accuracy: 0.9028\n",
      "Accuracy of our model on Train data :  90.28 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model on Train data : \" , round(model.evaluate(X_train,y_train)[1]*100,2) , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa772a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 11.3561 - accuracy: 0.5035\n",
      "Accuracy of our model on test data :  50.35 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model on test data : \" , round(model.evaluate(X_test,y_test)[1]*100,2) , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd7bf9",
   "metadata": {},
   "source": [
    "0 --> Angry\n",
    "1 --> Calm\n",
    "2 --> Disgust\n",
    "3 --> Fearful\n",
    "4 --> Happy\n",
    "5 --> Neutral\n",
    "6 --> Sad\n",
    "7 --> Surprised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e38ca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainVal_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ddd89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Angry', 'Calm', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47c70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/Users/hongtan/Downloads/inside_out_clip.mp4'\n",
    "output_srt_file = \"/Users/hongtan/Desktop/sentimentsub/website/sentsub/media/captions/audio.srt\"\n",
    "output_wav_file = \"/Users/hongtan/Downloads/output.wav\"\n",
    "output_folder = \"/Users/hongtan/Desktop/segmented-audio/\"\n",
    "\n",
    "insane_input_file = '/Users/hongtan/Desktop/sentimentsub/speech-to-text/audio-test-files/insane.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "376aea79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fearful'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running model on files\n",
    "audio_file = output_folder + '6.wav'\n",
    "audio_features = extract_features(audio_file)\n",
    "audio_features = np.expand_dims(audio_features, axis=1)\n",
    "audio_features.shape\n",
    "test = np.array([audio_features])\n",
    "prediction = model.predict(test)\n",
    "emotions[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SRT file\n",
    "import stable_whisper\n",
    "whisper_model = stable_whisper.load_model('base')\n",
    "result = whisper_model.transcribe(insane_input_file, fp16=False)\n",
    "result.to_srt_vtt(output_srt_file, word_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f761fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment mp4 file into multiple wav files according to SRT file\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Load audio file\n",
    "# sound = AudioSegment.from_file(input_file, format=\"mp4\")\n",
    "# sound = sound.set_channels(1)\n",
    "# sound.export(output_wav_file, format=\"wav\")\n",
    "audio = AudioSegment.from_wav(insane_input_file)\n",
    "\n",
    "# Parse SRT file\n",
    "with open(output_srt_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    subtitles = []\n",
    "    for line in lines:\n",
    "        if \"-->\" in line:\n",
    "            start, end = line.strip().split(\" --> \")\n",
    "            start = start.split(\":\")\n",
    "            end = end.split(\":\")\n",
    "            start = int(start[0]) * 3600 + int(start[1]) * 60 + float(start[2].replace(\",\", \".\"))\n",
    "            end = int(end[0]) * 3600 + int(end[1]) * 60 + float(end[2].replace(\",\", \".\"))\n",
    "            subtitles.append((start * 1000, end * 1000))\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Split audio file and export segments\n",
    "for i, (start, end) in enumerate(subtitles):\n",
    "    segment = audio[start:end]\n",
    "    segment.export(output_folder + str(i) + \".wav\", format=\"wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
